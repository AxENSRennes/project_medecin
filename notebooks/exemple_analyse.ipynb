{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutoriel : Analyse de donnees Eye-Tracking\n",
    "\n",
    "Ce notebook vous guide pas a pas dans l'analyse de donnees eye-tracking de l'etude SDS2.\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "A la fin de ce tutoriel, vous saurez :\n",
    "1. Charger et explorer les donnees brutes d'un eye-tracker Tobii\n",
    "2. Nettoyer et pre-traiter les donnees\n",
    "3. Calculer les metriques cles (fixations, saccades, pupilles)\n",
    "4. Creer des visualisations (cartes de chaleur, trajectoires)\n",
    "5. Comparer les groupes Patient vs Controle\n",
    "6. Integrer les donnees comportementales BORIS\n",
    "\n",
    "## Prerequis\n",
    "\n",
    "- Connaissance de base de Python (pandas, matplotlib)\n",
    "- Le projet installe (`pip install -e \".[dev]\"`)\n",
    "- Les donnees dans le dossier `Data/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 1 : Configuration et verification\n",
    "\n",
    "Commencons par importer les bibliotheques necessaires et verifier que tout est bien installe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports reussis !\n"
     ]
    }
   ],
   "source": [
    "# Imports standards Python\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Bibliotheques de manipulation de donnees\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Desactiver les warnings pour une lecture plus claire\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration matplotlib pour de beaux graphiques\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Imports reussis !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tobii_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Imports du pipeline tobii\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Ces modules sont le coeur du projet d'analyse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtobii_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_recording  \u001b[38;5;66;03m# Charger un fichier TSV\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtobii_pipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcleaner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clean_recording, filter_eye_tracker  \u001b[38;5;66;03m# Nettoyer les donnees\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtobii_pipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_filename  \u001b[38;5;66;03m# Extraire les metadonnees du nom de fichier\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tobii_pipeline'"
     ]
    }
   ],
   "source": [
    "# Imports du pipeline tobii\n",
    "# Ces modules sont le coeur du projet d'analyse\n",
    "\n",
    "from tobii_pipeline import load_recording  # Charger un fichier TSV\n",
    "from tobii_pipeline.cleaner import clean_recording, filter_eye_tracker  # Nettoyer les donnees\n",
    "from tobii_pipeline.parser import parse_filename  # Extraire les metadonnees du nom de fichier\n",
    "\n",
    "# Fonctions d'analyse\n",
    "from tobii_pipeline.analysis.metrics import (\n",
    "    compute_recording_summary,  # Calculer toutes les metriques\n",
    "    compute_validity_rate,      # Qualite des donnees\n",
    "    compute_gaze_dispersion,    # Dispersion du regard\n",
    "    compute_pupil_variability,  # Variabilite pupillaire\n",
    ")\n",
    "\n",
    "# Fonctions de visualisation\n",
    "from tobii_pipeline.analysis.plots import (\n",
    "    plot_recording_summary,  # Vue d'ensemble\n",
    "    plot_gaze_scatter,       # Points de regard\n",
    "    plot_pupil_timeseries,   # Evolution pupillaire\n",
    ")\n",
    "\n",
    "print(\"Pipeline tobii importe avec succes !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification de la presence des donnees\n",
    "# IMPORTANT : Vous devez avoir le dossier Data/ a la racine du projet\n",
    "\n",
    "# Chemins vers les donnees\n",
    "DATA_DIR = Path(\"../Data\")\n",
    "TOBII_DIRS = [DATA_DIR / \"data_G\" / \"Tobii\", DATA_DIR / \"data_L\" / \"Tobii\"]\n",
    "BORIS_DIRS = [DATA_DIR / \"data_G\" / \"Boris\", DATA_DIR / \"data_L\" / \"Boris\"]\n",
    "\n",
    "# Verifier que les dossiers existent\n",
    "if not DATA_DIR.exists():\n",
    "    print(\"ATTENTION : Le dossier Data/ n'existe pas !\")\n",
    "    print(\"Veuillez placer vos donnees dans le dossier Data/ a la racine du projet.\")\n",
    "    print(\"Structure attendue :\")\n",
    "    print(\"  Data/\")\n",
    "    print(\"    data_G/\")\n",
    "    print(\"      Tobii/  <- fichiers .tsv\")\n",
    "    print(\"      Boris/  <- fichiers .xlsx\")\n",
    "    print(\"    data_L/\")\n",
    "    print(\"      Tobii/\")\n",
    "    print(\"      Boris/\")\n",
    "else:\n",
    "    # Compter les fichiers disponibles\n",
    "    tobii_files = []\n",
    "    for d in TOBII_DIRS:\n",
    "        if d.exists():\n",
    "            tobii_files.extend(list(d.glob(\"*.tsv\")))\n",
    "    \n",
    "    print(f\"Donnees trouvees : {len(tobii_files)} fichiers Tobii\")\n",
    "    \n",
    "    if tobii_files:\n",
    "        print(\"\\nExemples de fichiers :\")\n",
    "        for f in tobii_files[:3]:\n",
    "            print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 2 : Chargement d'un enregistrement\n",
    "\n",
    "Un enregistrement = une session d'eye-tracking d'un participant a une visite donnee.\n",
    "\n",
    "Le fichier TSV contient toutes les mesures capturees par le Tobii a 100 Hz (100 mesures par seconde)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectionner un fichier pour l'analyse\n",
    "# Nous allons utiliser le premier fichier disponible\n",
    "\n",
    "if not tobii_files:\n",
    "    raise FileNotFoundError(\"Aucun fichier Tobii trouve. Ajoutez vos donnees dans Data/\")\n",
    "\n",
    "# Prendre le premier fichier comme exemple\n",
    "fichier_exemple = tobii_files[0]\n",
    "print(f\"Fichier selectionne : {fichier_exemple.name}\")\n",
    "\n",
    "# Extraire les metadonnees du nom de fichier\n",
    "# Le nom suit la convention : ID_Participant_Etude_Groupe_Mois_Visite_Date\n",
    "metadata = parse_filename(fichier_exemple.name)\n",
    "\n",
    "print(\"\\nMetadonnees extraites :\")\n",
    "for cle, valeur in metadata.items():\n",
    "    print(f\"  {cle}: {valeur}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donnees brutes\n",
    "# La fonction load_recording() lit le fichier TSV et le convertit en DataFrame pandas\n",
    "\n",
    "print(\"Chargement en cours...\")\n",
    "df_brut = load_recording(fichier_exemple)\n",
    "\n",
    "print(f\"\\nDonnees chargees : {len(df_brut):,} lignes x {len(df_brut.columns)} colonnes\")\n",
    "print(f\"Duree approximative : {len(df_brut) / 100:.1f} secondes (a 100 Hz)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorer la structure des donnees\n",
    "# Chaque ligne = une mesure (1/100e de seconde)\n",
    "# Chaque colonne = un type de mesure\n",
    "\n",
    "print(\"Apercu des premieres lignes :\")\n",
    "df_brut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes disponibles\n",
    "# Le Tobii capture beaucoup d'informations differentes\n",
    "\n",
    "print(f\"Colonnes disponibles ({len(df_brut.columns)}) :\\n\")\n",
    "\n",
    "# Grouper les colonnes par categorie pour plus de clarte\n",
    "colonnes_importantes = {\n",
    "    \"Temps\": [\"Recording timestamp\"],\n",
    "    \"Position du regard\": [\"Gaze point X\", \"Gaze point Y\"],\n",
    "    \"Pupilles\": [\"Pupil diameter left\", \"Pupil diameter right\"],\n",
    "    \"Validite\": [\"Validity left\", \"Validity right\"],\n",
    "    \"Capteur\": [\"Sensor\"],\n",
    "}\n",
    "\n",
    "for categorie, colonnes in colonnes_importantes.items():\n",
    "    print(f\"{categorie}:\")\n",
    "    for col in colonnes:\n",
    "        if col in df_brut.columns:\n",
    "            print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprendre les colonnes cles\n",
    "\n",
    "| Colonne | Description | Unite |\n",
    "|---------|-------------|-------|\n",
    "| `Recording timestamp` | Temps depuis le debut | Microsecondes |\n",
    "| `Gaze point X`, `Gaze point Y` | Position du regard sur l'ecran | Pixels (0-1920, 0-1080) |\n",
    "| `Pupil diameter left/right` | Taille des pupilles | Millimetres |\n",
    "| `Validity left/right` | Qualite de la mesure | \"Valid\" ou \"Invalid\" |\n",
    "| `Sensor` | Type de capteur | \"Eye Tracker\", \"Accelerometer\", etc. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 3 : Nettoyage des donnees\n",
    "\n",
    "Les donnees brutes necessitent un nettoyage avant analyse :\n",
    "1. **Conversion des decimales** : Le Tobii exporte avec des virgules (format europeen)\n",
    "2. **Filtrage** : Garder uniquement les donnees de l'eye-tracker (pas l'accelerometre)\n",
    "3. **Validation** : Identifier les mesures invalides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 1 : Nettoyage de base\n",
    "# La fonction clean_recording() gere automatiquement :\n",
    "# - La conversion des virgules en points (3,14 -> 3.14)\n",
    "# - La conversion des types de donnees\n",
    "\n",
    "df_propre = clean_recording(df_brut)\n",
    "\n",
    "# Verifier que les colonnes numeriques sont bien converties\n",
    "print(\"Types de donnees apres nettoyage :\")\n",
    "print(df_propre[[\"Gaze point X\", \"Pupil diameter left\"]].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 2 : Filtrer pour ne garder que les donnees eye-tracker\n",
    "# Le fichier contient aussi des donnees d'accelerometre et gyroscope\n",
    "# que nous n'utilisons pas pour l'analyse du regard\n",
    "\n",
    "print(\"Types de capteurs dans les donnees :\")\n",
    "print(df_propre[\"Sensor\"].value_counts())\n",
    "\n",
    "# Filtrer\n",
    "df = filter_eye_tracker(df_propre)\n",
    "\n",
    "print(f\"\\nApres filtrage : {len(df):,} lignes (vs {len(df_propre):,} avant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 3 : Evaluer la qualite des donnees\n",
    "# La colonne \"Validity\" indique si le Tobii a reussi a detecter l'oeil\n",
    "\n",
    "# Calculer le taux de validite (% de mesures exploitables)\n",
    "taux_validite = compute_validity_rate(df)\n",
    "\n",
    "print(f\"Taux de validite : {taux_validite:.1%}\")\n",
    "\n",
    "if taux_validite > 0.8:\n",
    "    print(\"Bonne qualite de donnees\")\n",
    "elif taux_validite > 0.5:\n",
    "    print(\"Qualite acceptable, mais des donnees sont manquantes\")\n",
    "else:\n",
    "    print(\"Attention : beaucoup de donnees manquantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les donnees manquantes au cours du temps\n",
    "# Cela permet de voir si les pertes de signal sont concentrees ou dispersees\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "# Creer un indicateur de validite (1 = valide, 0 = invalide)\n",
    "validite = ((df[\"Validity left\"] == \"Valid\") & (df[\"Validity right\"] == \"Valid\")).astype(int)\n",
    "\n",
    "# Calculer la moyenne mobile sur 1 seconde (100 echantillons)\n",
    "validite_lissee = validite.rolling(window=100, min_periods=1).mean()\n",
    "\n",
    "# Convertir le temps en secondes\n",
    "temps_secondes = (df[\"Recording timestamp\"] - df[\"Recording timestamp\"].iloc[0]) / 1_000_000\n",
    "\n",
    "ax.fill_between(temps_secondes, validite_lissee, alpha=0.7, color='steelblue')\n",
    "ax.set_xlabel(\"Temps (secondes)\")\n",
    "ax.set_ylabel(\"Taux de validite\")\n",
    "ax.set_title(\"Qualite du signal au cours de l'enregistrement\")\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Seuil 80%')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 4 : Calcul des metriques\n",
    "\n",
    "Maintenant que les donnees sont propres, calculons les metriques cles qui caracterisent le comportement visuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer toutes les metriques d'un coup\n",
    "# La fonction compute_recording_summary() fait tout le travail :\n",
    "# - Detection des fixations et saccades (via pymovements)\n",
    "# - Statistiques pupillaires\n",
    "# - Metriques de qualite\n",
    "\n",
    "print(\"Calcul des metriques en cours...\")\n",
    "print(\"(Cela peut prendre quelques secondes pour la detection des evenements)\")\n",
    "\n",
    "metriques = compute_recording_summary(df)\n",
    "\n",
    "print(\"\\nCalcul termine !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les metriques de facon structuree\n",
    "# Les metriques sont organisees en categories\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUME DES METRIQUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Qualite des donnees\n",
    "print(\"\\n--- QUALITE ---\")\n",
    "qualite = metriques.get(\"quality\", {})\n",
    "print(f\"  Taux de validite (2 yeux) : {qualite.get('validity_rate', 0):.1%}\")\n",
    "print(f\"  Taux de validite (1 oeil) : {qualite.get('validity_rate_either', 0):.1%}\")\n",
    "\n",
    "# Regard\n",
    "print(\"\\n--- REGARD ---\")\n",
    "regard = metriques.get(\"gaze\", {})\n",
    "centre = regard.get(\"center\", (np.nan, np.nan))\n",
    "print(f\"  Centre moyen : ({centre[0]:.0f}, {centre[1]:.0f}) pixels\")\n",
    "print(f\"  Dispersion : {regard.get('dispersion', np.nan):.1f} pixels\")\n",
    "\n",
    "# Pupilles\n",
    "print(\"\\n--- PUPILLES ---\")\n",
    "pupille = metriques.get(\"pupil\", {})\n",
    "stats_pupille = pupille.get(\"stats\", {})\n",
    "print(f\"  Diametre moyen : {stats_pupille.get('mean', np.nan):.2f} mm\")\n",
    "print(f\"  Variabilite (CV) : {pupille.get('variability', np.nan):.3f}\")\n",
    "\n",
    "# Fixations\n",
    "print(\"\\n--- FIXATIONS ---\")\n",
    "fixation = metriques.get(\"fixation\", {})\n",
    "print(f\"  Nombre : {fixation.get('count', 0)}\")\n",
    "print(f\"  Duree moyenne : {fixation.get('duration_mean_ms', np.nan):.0f} ms\")\n",
    "\n",
    "# Saccades\n",
    "print(\"\\n--- SACCADES ---\")\n",
    "saccade = metriques.get(\"saccade\", {})\n",
    "print(f\"  Nombre : {saccade.get('count', 0)}\")\n",
    "print(f\"  Amplitude moyenne : {saccade.get('amplitude_mean_deg', np.nan):.1f} degres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation des metriques\n",
    "\n",
    "- **Dispersion elevee** (> 300 px) : Le regard explore largement l'ecran\n",
    "- **Fixations longues** (> 400 ms) : Traitement visuel approfondi ou difficulte\n",
    "- **Variabilite pupillaire elevee** (> 0.15) : Charge cognitive fluctuante\n",
    "- **Beaucoup de saccades** : Exploration active, recherche visuelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 5 : Visualisations\n",
    "\n",
    "Les graphiques permettent de comprendre intuitivement le comportement visuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vue d'ensemble complete de l'enregistrement\n",
    "# Cette fonction genere plusieurs graphiques en un seul appel\n",
    "\n",
    "fig = plot_recording_summary(df, figsize=(16, 12))\n",
    "\n",
    "# Ajouter un titre avec les informations du participant\n",
    "titre = f\"Participant: {metadata.get('participant', '?')} | \"\n",
    "titre += f\"Groupe: {metadata.get('group', '?')} | \"\n",
    "titre += f\"Visite: M{metadata.get('month', '?')}\"\n",
    "fig.suptitle(titre, fontsize=14, y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carte de chaleur du regard (heatmap)\n",
    "# Montre ou le participant a regarde le plus souvent\n",
    "# Les zones chaudes (jaune/rouge) = plus regardees\n",
    "\n",
    "from tobii_pipeline.adapters.mne_adapter import create_gaze_heatmap_mne\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Extraire les positions de regard valides\n",
    "masque_valide = (df[\"Validity left\"] == \"Valid\") | (df[\"Validity right\"] == \"Valid\")\n",
    "x = df.loc[masque_valide, \"Gaze point X\"].dropna()\n",
    "y = df.loc[masque_valide, \"Gaze point Y\"].dropna()\n",
    "\n",
    "# Creer la heatmap\n",
    "create_gaze_heatmap_mne(x.values, y.values, ax=ax, screen_size=(1920, 1080))\n",
    "\n",
    "ax.set_title(\"Carte de chaleur du regard\")\n",
    "ax.set_xlabel(\"Position X (pixels)\")\n",
    "ax.set_ylabel(\"Position Y (pixels)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution du diametre pupillaire au cours du temps\n",
    "# La pupille se dilate avec l'effort mental et se contracte avec la lumiere\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Convertir le temps en secondes\n",
    "temps = (df[\"Recording timestamp\"] - df[\"Recording timestamp\"].iloc[0]) / 1_000_000\n",
    "\n",
    "# Tracer les deux yeux\n",
    "ax.plot(temps, df[\"Pupil diameter left\"], alpha=0.5, label=\"Oeil gauche\", linewidth=0.5)\n",
    "ax.plot(temps, df[\"Pupil diameter right\"], alpha=0.5, label=\"Oeil droit\", linewidth=0.5)\n",
    "\n",
    "# Ajouter une moyenne mobile pour voir la tendance\n",
    "moyenne_gauche = df[\"Pupil diameter left\"].rolling(window=500, min_periods=1).mean()\n",
    "ax.plot(temps, moyenne_gauche, color='blue', linewidth=2, label=\"Tendance (gauche)\")\n",
    "\n",
    "ax.set_xlabel(\"Temps (secondes)\")\n",
    "ax.set_ylabel(\"Diametre pupillaire (mm)\")\n",
    "ax.set_title(\"Evolution du diametre pupillaire\")\n",
    "ax.legend()\n",
    "ax.set_ylim(2, 8)  # Plage physiologique normale\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 6 : Comparaison Patient vs Controle\n",
    "\n",
    "L'objectif principal de l'etude est de comparer les comportements visuels entre les deux groupes.\n",
    "Pour cela, nous devons charger plusieurs enregistrements et calculer leurs metriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et analyser plusieurs enregistrements\n",
    "# ATTENTION : Cette cellule peut prendre plusieurs minutes\n",
    "\n",
    "from tqdm.notebook import tqdm  # Barre de progression\n",
    "\n",
    "# Limiter le nombre de fichiers pour l'exemple (ajustez selon vos besoins)\n",
    "MAX_FICHIERS = 10  # Mettre None pour tout charger\n",
    "\n",
    "fichiers_a_analyser = tobii_files[:MAX_FICHIERS] if MAX_FICHIERS else tobii_files\n",
    "print(f\"Analyse de {len(fichiers_a_analyser)} enregistrements...\")\n",
    "\n",
    "resultats = []\n",
    "\n",
    "for fichier in tqdm(fichiers_a_analyser, desc=\"Analyse\"):\n",
    "    try:\n",
    "        # Charger et nettoyer\n",
    "        df_temp = load_recording(fichier, nrows=50000)  # Limiter les lignes pour accelerer\n",
    "        df_temp = clean_recording(df_temp)\n",
    "        df_temp = filter_eye_tracker(df_temp)\n",
    "        \n",
    "        # Extraire les metadonnees\n",
    "        meta = parse_filename(fichier.name)\n",
    "        \n",
    "        # Calculer les metriques\n",
    "        metriques_temp = compute_recording_summary(df_temp)\n",
    "        \n",
    "        # Stocker les resultats\n",
    "        resultats.append({\n",
    "            \"fichier\": fichier.name,\n",
    "            \"participant\": meta.get(\"participant\", \"\"),\n",
    "            \"groupe\": \"Patient\" if meta.get(\"group\") == \"P\" else \"Controle\",\n",
    "            \"mois\": meta.get(\"month\", 0),\n",
    "            \"validity_rate\": metriques_temp.get(\"quality\", {}).get(\"validity_rate\", np.nan),\n",
    "            \"gaze_dispersion\": metriques_temp.get(\"gaze\", {}).get(\"dispersion\", np.nan),\n",
    "            \"pupil_variability\": metriques_temp.get(\"pupil\", {}).get(\"variability\", np.nan),\n",
    "            \"fixation_count\": metriques_temp.get(\"fixation\", {}).get(\"count\", 0),\n",
    "            \"fixation_duration\": metriques_temp.get(\"fixation\", {}).get(\"duration_mean_ms\", np.nan),\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec {fichier.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df_resultats = pd.DataFrame(resultats)\n",
    "print(f\"\\n{len(df_resultats)} enregistrements analyses avec succes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un apercu des resultats\n",
    "df_resultats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les groupes\n",
    "# Calculer les moyennes par groupe\n",
    "\n",
    "if len(df_resultats) > 0 and \"groupe\" in df_resultats.columns:\n",
    "    comparaison = df_resultats.groupby(\"groupe\").agg({\n",
    "        \"validity_rate\": [\"mean\", \"std\", \"count\"],\n",
    "        \"gaze_dispersion\": [\"mean\", \"std\"],\n",
    "        \"pupil_variability\": [\"mean\", \"std\"],\n",
    "        \"fixation_duration\": [\"mean\", \"std\"],\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"\\nComparaison Patient vs Controle :\")\n",
    "    print(comparaison)\n",
    "else:\n",
    "    print(\"Pas assez de donnees pour la comparaison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation : Comparaison des distributions\n",
    "\n",
    "if len(df_resultats) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    metriques_a_comparer = [\n",
    "        (\"gaze_dispersion\", \"Dispersion du regard (px)\"),\n",
    "        (\"pupil_variability\", \"Variabilite pupillaire (CV)\"),\n",
    "        (\"fixation_duration\", \"Duree des fixations (ms)\"),\n",
    "        (\"fixation_count\", \"Nombre de fixations\"),\n",
    "    ]\n",
    "    \n",
    "    couleurs = {\"Patient\": \"#e74c3c\", \"Controle\": \"#3498db\"}\n",
    "    \n",
    "    for ax, (col, titre) in zip(axes.flatten(), metriques_a_comparer):\n",
    "        for groupe in [\"Patient\", \"Controle\"]:\n",
    "            donnees = df_resultats[df_resultats[\"groupe\"] == groupe][col].dropna()\n",
    "            if len(donnees) > 0:\n",
    "                ax.hist(donnees, alpha=0.6, label=groupe, color=couleurs[groupe], bins=10)\n",
    "        \n",
    "        ax.set_xlabel(titre)\n",
    "        ax.set_ylabel(\"Frequence\")\n",
    "        ax.legend()\n",
    "        ax.set_title(f\"Distribution : {titre}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Pas assez de donnees pour la visualisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 7 : Analyse longitudinale\n",
    "\n",
    "L'etude suit les participants sur 36 mois. Observons comment les metriques evoluent dans le temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution des metriques au cours du temps\n",
    "\n",
    "if len(df_resultats) > 0 and \"mois\" in df_resultats.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    for ax, (col, titre) in zip(axes.flatten(), metriques_a_comparer):\n",
    "        for groupe in [\"Patient\", \"Controle\"]:\n",
    "            donnees_groupe = df_resultats[df_resultats[\"groupe\"] == groupe]\n",
    "            \n",
    "            # Calculer la moyenne par mois\n",
    "            moyennes = donnees_groupe.groupby(\"mois\")[col].mean()\n",
    "            \n",
    "            if len(moyennes) > 0:\n",
    "                ax.plot(moyennes.index, moyennes.values, \n",
    "                       'o-', label=groupe, color=couleurs[groupe], \n",
    "                       linewidth=2, markersize=8)\n",
    "        \n",
    "        ax.set_xlabel(\"Mois\")\n",
    "        ax.set_ylabel(titre)\n",
    "        ax.set_title(f\"Evolution : {titre}\")\n",
    "        ax.legend()\n",
    "        ax.set_xticks([0, 12, 24, 36])\n",
    "        ax.set_xticklabels([\"M0\", \"M12\", \"M24\", \"M36\"])\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Pas assez de donnees pour l'analyse longitudinale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 8 : Integration des donnees BORIS (optionnel)\n",
    "\n",
    "Les donnees BORIS contiennent le codage comportemental realise par les observateurs.\n",
    "Cela permet de croiser les metriques eye-tracking avec les comportements observes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifier la disponibilite des donnees BORIS\n",
    "\n",
    "boris_files = []\n",
    "for d in BORIS_DIRS:\n",
    "    if d.exists():\n",
    "        boris_files.extend(list(d.glob(\"*_agregated.xlsx\")))\n",
    "\n",
    "print(f\"Fichiers BORIS trouves : {len(boris_files)}\")\n",
    "\n",
    "if boris_files:\n",
    "    print(\"\\nExemples :\")\n",
    "    for f in boris_files[:3]:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger un fichier BORIS\n",
    "\n",
    "if boris_files:\n",
    "    from boris_pipeline import load_boris_file\n",
    "    \n",
    "    boris_exemple = boris_files[0]\n",
    "    print(f\"Chargement de : {boris_exemple.name}\")\n",
    "    \n",
    "    df_boris = load_boris_file(boris_exemple, file_type=\"aggregated\")\n",
    "    \n",
    "    print(f\"\\n{len(df_boris)} evenements comportementaux\")\n",
    "    print(\"\\nColonnes :\")\n",
    "    print(df_boris.columns.tolist())\n",
    "    \n",
    "    print(\"\\nApercu :\")\n",
    "    display(df_boris.head())\n",
    "else:\n",
    "    print(\"Pas de fichiers BORIS disponibles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorer les comportements codes\n",
    "\n",
    "if boris_files and 'df_boris' in dir():\n",
    "    print(\"Comportements observes :\")\n",
    "    print(df_boris[\"Behavior\"].value_counts())\n",
    "else:\n",
    "    print(\"Donnees BORIS non disponibles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'analyse croisee : diametre pupillaire par comportement\n",
    "\n",
    "if boris_files and 'df_boris' in dir():\n",
    "    from integration.cross_modal import compute_pupil_per_behavior\n",
    "    \n",
    "    # Utiliser le meme participant pour les deux sources de donnees\n",
    "    # (le fichier Tobii charge au debut du notebook)\n",
    "    \n",
    "    try:\n",
    "        pupil_par_comportement = compute_pupil_per_behavior(df, df_boris)\n",
    "        \n",
    "        print(\"Diametre pupillaire moyen par comportement :\")\n",
    "        for comportement, stats in pupil_par_comportement.items():\n",
    "            if isinstance(stats, dict) and 'mean' in stats:\n",
    "                print(f\"  {comportement}: {stats['mean']:.2f} mm\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'analyse croisee : {e}\")\n",
    "        print(\"(Les fichiers Tobii et BORIS doivent correspondre au meme participant)\")\n",
    "else:\n",
    "    print(\"Donnees BORIS non disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 9 : Conclusion et prochaines etapes\n",
    "\n",
    "### Ce que nous avons appris\n",
    "\n",
    "1. **Chargement** : Les fichiers Tobii TSV contiennent des mesures a 100 Hz\n",
    "2. **Nettoyage** : Conversion des decimales et filtrage necessaires\n",
    "3. **Metriques** : Fixations, saccades, pupilles caracterisent le comportement visuel\n",
    "4. **Visualisation** : Heatmaps et timeseries revelent les patterns\n",
    "5. **Comparaison** : Tests statistiques pour detecter les differences entre groupes\n",
    "6. **Integration** : BORIS permet de lier eye-tracking et comportement\n",
    "\n",
    "### Pour aller plus loin\n",
    "\n",
    "- **Scripts automatises** : Utilisez `run_analysis.py` pour des analyses completes\n",
    "- **Figures de publication** : Le module `pub_plots.py` genere des graphiques professionnels\n",
    "- **Tests statistiques** : Le module `stats.py` contient t-tests, Mann-Whitney, etc.\n",
    "- **Preprocessing avance** : `postprocess.py` gere interpolation, clignements, outliers\n",
    "\n",
    "### Ressources\n",
    "\n",
    "- Documentation technique : `CLAUDE.md` a la racine du projet\n",
    "- README detaille : `README.md` avec explications en francais\n",
    "- Tests : `pytest` pour verifier l'installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tutoriel termine ! Bonne analyse.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
